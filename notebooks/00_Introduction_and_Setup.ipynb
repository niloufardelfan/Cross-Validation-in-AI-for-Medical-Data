{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba6169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated DataFrame shape: (500, 22)\n",
      "Value counts for target variable:\n",
      "target\n",
      "0    387\n",
      "1    113\n",
      "Name: count, dtype: int64\n",
      "Number of unique patients: 100\n",
      "Samples per patient (distribution):\n",
      "count    100.0\n",
      "mean       5.0\n",
      "std        0.0\n",
      "min        5.0\n",
      "25%        5.0\n",
      "50%        5.0\n",
      "75%        5.0\n",
      "max        5.0\n",
      "Name: count, dtype: float64\n",
      "--- Dataset Shapes ---\n",
      "Development Features (X_dev):   (400, 20)\n",
      "Development Target (y_dev):     (400,)\n",
      "Development Groups (groups_dev):(400,)\n",
      "--------------------\n",
      "Test Features (X_test):         (100, 20)\n",
      "Test Target (y_test):           (100,)\n",
      "Test Groups (groups_test):      (100,)\n",
      "--------------------\n",
      "Development set class proportions: [0.775 0.225]\n",
      "Test set class proportions:        [0.77 0.23]\n",
      "\n",
      "Number of patients in Dev set: 100\n",
      "Number of patients in Test set: 71\n",
      "Number of patients common to both sets: 71\n",
      "WARNING: Patients ended up in both Dev and Test sets! Review split logic if patient-level split is needed here.\n"
     ]
    }
   ],
   "source": [
    "# # Notebook 0: Introduction, Overfitting, and Data Setup\n",
    "#\n",
    "# ## Goals\n",
    "# * Understand the fundamental problem of overfitting in machine learning.\n",
    "# * Understand the concept of generalization error.\n",
    "# * Learn the importance of splitting data into Training, Validation, and Test sets.\n",
    "# * Generate synthetic data for demonstrating cross-validation concepts, including features, a target variable, and crucial group identifiers (simulating patients).\n",
    "# * Perform the initial Train/Test split to isolate the final hold-out test set.\n",
    "\n",
    "# ## 1. The Problem: Overfitting and Generalization\n",
    "#\n",
    "# In supervised machine learning, our goal is to build a model that learns patterns from labeled data (training data) to make predictions on new, unseen data.\n",
    "#\n",
    "# **Overfitting** occurs when a model learns the training data *too well*. It memorizes the specific examples, including noise and random fluctuations, rather than learning the underlying general patterns.\n",
    "#\n",
    "# **Analogy:** Imagine studying for an exam by memorizing the answers to only last year's questions. You might ace those exact questions if they reappear, but you'll likely fail on new questions because you didn't learn the *concepts*. An overfitted model is like this student.\n",
    "#\n",
    "# **Consequences:** An overfitted model performs excellently on the data it was trained on, but poorly on new data it hasn't seen before.\n",
    "#\n",
    "# **Generalization Error:** This measures how accurately a model performs on new, unseen data drawn from the same distribution as the training data. Our **true goal** in machine learning is to minimize generalization error, not just the error on the training set.\n",
    "\n",
    "# ## 2. The Solution: Train/Validation/Test Split\n",
    "#\n",
    "# To estimate generalization error and develop models that perform well on new data, we split our dataset:\n",
    "#\n",
    "# 1.  **Training Set:** Used to train the model (i.e., learn the parameters).\n",
    "# 2.  **Validation Set (or Development Set):** Used *during* model development to:\n",
    "#     *   Tune hyperparameters (e.g., complexity settings of the model).\n",
    "#     *   Select features.\n",
    "#     *   Get an *intermediate*, unbiased estimate of model performance to guide development choices. Cross-validation techniques systematically create validation sets.\n",
    "# 3.  **Test Set (Hold-out Set):** Used *only once* at the very end of the development process, after the model is finalized (including hyperparameter choices). It provides the *final, unbiased estimate* of the chosen model's generalization performance. **This data must not influence training or tuning decisions.**\n",
    "#\n",
    "# ```\n",
    "# +------------------------------------------+\n",
    "# |           Original Dataset               |\n",
    "# +------------------------------------------+\n",
    "#      |\n",
    "#      | Split (e.g., 80/20)\n",
    "#      V\n",
    "# +------------------------+   +-------------+\n",
    "# |  Development Data      |   |  Test Set   |  <- Hold-out! Use only ONCE at the end.\n",
    "# |  (Train + Validation)  |   |  (e.g. 20%) |\n",
    "# |  (e.g. 80%)            |   +-------------+\n",
    "# +------------------------+\n",
    "#      |\n",
    "#      | (Cross-Validation happens HERE)\n",
    "#      V\n",
    "# +-----------------+   +-----------------+\n",
    "# |  Training Fold  |   | Validation Fold |  <- Repeated K times in K-Fold CV\n",
    "# +-----------------+   +-----------------+\n",
    "# ```\n",
    "\n",
    "# ## 3. Setup and Data Generation\n",
    "#\n",
    "# Let's import necessary libraries and generate some synthetic data that mimics characteristics often found in medical datasets, such as classification tasks and multiple samples per patient (group).\n",
    "\n",
    "# +\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Settings for data generation\n",
    "N_SAMPLES = 500       # Total number of data points (e.g., images, tests)\n",
    "N_FEATURES = 20       # Number of input features\n",
    "N_CLASSES = 2         # Binary classification task (e.g., disease vs. healthy)\n",
    "N_PATIENTS = 100      # Number of unique patients/groups\n",
    "IMBALANCE = 0.8       # Fraction of the majority class (e.g., 80% healthy)\n",
    "\n",
    "RANDOM_STATE = 42     # For reproducibility\n",
    "\n",
    "# Generate features and target variable\n",
    "# Using make_classification for a slightly more complex dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_features=N_FEATURES,\n",
    "    n_informative=10,    # Number of features that actually contain signal\n",
    "    n_redundant=5,\n",
    "    n_repeated=0,\n",
    "    n_classes=N_CLASSES,\n",
    "    n_clusters_per_class=2,\n",
    "    weights=[IMBALANCE, 1.0 - IMBALANCE], # Class imbalance\n",
    "    flip_y=0.05,          # Add some noise to labels\n",
    "    class_sep=0.8,        # How separable the classes are\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Generate Patient/Group IDs\n",
    "# Ensure each patient has roughly the same number of samples\n",
    "samples_per_patient = N_SAMPLES // N_PATIENTS\n",
    "groups = np.repeat(np.arange(N_PATIENTS), samples_per_patient)\n",
    "\n",
    "# If N_SAMPLES is not perfectly divisible by N_PATIENTS, assign remaining samples\n",
    "remaining_samples = N_SAMPLES % N_PATIENTS\n",
    "if remaining_samples > 0:\n",
    "    groups = np.concatenate([groups, np.random.choice(N_PATIENTS, remaining_samples)]) # Assign randomly\n",
    "\n",
    "# Shuffle groups array to mix patients (X, y are already shuffled by make_classification)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "np.random.shuffle(groups) # Shuffle the group assignments while keeping X, y aligned initially\n",
    "\n",
    "# Create a DataFrame (optional, but good practice)\n",
    "feature_names = [f'feature_{i+1}' for i in range(N_FEATURES)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "df['patient_id'] = groups\n",
    "\n",
    "print(f\"Generated DataFrame shape: {df.shape}\")\n",
    "print(f\"Value counts for target variable:\\n{df['target'].value_counts()}\")\n",
    "print(f\"Number of unique patients: {df['patient_id'].nunique()}\")\n",
    "print(f\"Samples per patient (distribution):\\n{df['patient_id'].value_counts().describe()}\")\n",
    "df.head()\n",
    "# -\n",
    "\n",
    "# ## 4. Perform the Initial Train/Test Split\n",
    "#\n",
    "# We will now split off the **final hold-out test set**. This set (`X_test`, `y_test`, `groups_test`) will **not be touched** during any cross-validation or hyperparameter tuning steps demonstrated in the subsequent notebooks. We must also keep track of the patient IDs corresponding to the test set.\n",
    "#\n",
    "# We use `stratify=y` to ensure the class proportions are roughly maintained in both the development and test sets, which is important for imbalanced datasets.\n",
    "\n",
    "# +\n",
    "# Define features (X), target (y), and groups\n",
    "X = df.drop(['target', 'patient_id'], axis=1).values\n",
    "y = df['target'].values\n",
    "groups = df['patient_id'].values\n",
    "\n",
    "# Split data into Development (Train+Validation) and Test sets\n",
    "# Using 80% for development, 20% for the final test set\n",
    "test_set_size = 0.20\n",
    "\n",
    "X_dev, X_test, y_dev, y_test, groups_dev, groups_test = train_test_split(\n",
    "    X, y, groups,\n",
    "    test_size=test_set_size,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y # Stratify based on the target variable 'y'\n",
    ")\n",
    "\n",
    "print(\"--- Dataset Shapes ---\")\n",
    "print(f\"Development Features (X_dev):   {X_dev.shape}\")\n",
    "print(f\"Development Target (y_dev):     {y_dev.shape}\")\n",
    "print(f\"Development Groups (groups_dev):{groups_dev.shape}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Test Features (X_test):         {X_test.shape}\")\n",
    "print(f\"Test Target (y_test):           {y_test.shape}\")\n",
    "print(f\"Test Groups (groups_test):      {groups_test.shape}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Verify stratification (optional)\n",
    "dev_prop = np.bincount(y_dev) / len(y_dev)\n",
    "test_prop = np.bincount(y_test) / len(y_test)\n",
    "print(f\"Development set class proportions: {dev_prop}\")\n",
    "print(f\"Test set class proportions:        {test_prop}\")\n",
    "\n",
    "# Verify patient separation (Important check!)\n",
    "dev_patients = set(groups_dev)\n",
    "test_patients = set(groups_test)\n",
    "common_patients = dev_patients.intersection(test_patients)\n",
    "print(f\"\\nNumber of patients in Dev set: {len(dev_patients)}\")\n",
    "print(f\"Number of patients in Test set: {len(test_patients)}\")\n",
    "print(f\"Number of patients common to both sets: {len(common_patients)}\")\n",
    "if len(common_patients) > 0:\n",
    "    print(\"WARNING: Patients ended up in both Dev and Test sets! Review split logic if patient-level split is needed here.\")\n",
    "    # NOTE: Standard train_test_split does NOT guarantee patient-level separation.\n",
    "    # We will handle proper patient-level splitting *within* the Development set using GroupKFold later.\n",
    "    # The separation check here is mainly illustrative for now. For a strict patient-level *initial* split,\n",
    "    # you'd need GroupShuffleSplit or similar logic applied once.\n",
    "else:\n",
    "    print(\"OK: No patients shared between Dev and Test sets (based on this split).\")\n",
    "\n",
    "# Save the split data for use in other notebooks (Optional, could also pass variables if running sequentially)\n",
    "# We'll assume variables X_dev, y_dev, groups_dev, X_test, y_test are available conceptually\n",
    "# %store X_dev y_dev groups_dev X_test y_test groups_test\n",
    "# -\n",
    "\n",
    "# ## 5. Next Steps\n",
    "#\n",
    "# We now have our development dataset (`X_dev`, `y_dev`, `groups_dev`) which we will use in the subsequent notebooks to demonstrate various cross-validation techniques. The `X_test`, `y_test` data is set aside and should only be used for a final evaluation after all model development and selection is complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
