{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Notebook 1: Basic Cross-Validation Strategies\n",
    "#\n",
    "# ## Goals\n",
    "# * Understand the limitations of a single validation split (Hold-Out).\n",
    "# * Implement and understand K-Fold Cross-Validation.\n",
    "# * Implement and understand Stratified K-Fold Cross-Validation (crucial for classification).\n",
    "# * Implement and understand Leave-One-Out Cross-Validation (LOOCV).\n",
    "# * Use `sklearn.model_selection.cross_val_score` for convenient CV evaluation.\n",
    "#\n",
    "# We will use the **Development Set** (`X_dev`, `y_dev`) created in Notebook 0. The Test Set remains untouched.\n",
    "\n",
    "# ## 1. Setup and Loading Data\n",
    "#\n",
    "# Let's import libraries and load the development data we prepared.\n",
    "\n",
    "# +\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    LeaveOneOut,\n",
    "    cross_val_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "# %matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Assume X_dev, y_dev, groups_dev are loaded from Notebook 0\n",
    "# If you didn't use %store or are running standalone, regenerate or load them here.\n",
    "# Example using %store:\n",
    "# %store -r X_dev y_dev groups_dev X_test y_test groups_test\n",
    "\n",
    "# For standalone running, let's quickly regenerate similar data:\n",
    "RANDOM_STATE = 42\n",
    "try:\n",
    "    X_dev.shape # Check if variable exists\n",
    "    print(\"Using data loaded from previous notebook.\")\n",
    "except NameError:\n",
    "    print(\"Generating synthetic data for standalone execution...\")\n",
    "    from sklearn.datasets import make_classification\n",
    "    N_SAMPLES_DEV = 400 # Assuming 80% of 500\n",
    "    N_FEATURES = 20\n",
    "    N_CLASSES = 2\n",
    "    N_PATIENTS_DEV = 80 # Rough estimate\n",
    "    IMBALANCE = 0.8\n",
    "    X_dev, y_dev = make_classification(\n",
    "        n_samples=N_SAMPLES_DEV, n_features=N_FEATURES, n_informative=10, n_redundant=5, n_repeated=0,\n",
    "        n_classes=N_CLASSES, n_clusters_per_class=2, weights=[IMBALANCE, 1.0 - IMBALANCE],\n",
    "        flip_y=0.05, class_sep=0.8, random_state=RANDOM_STATE\n",
    "    )\n",
    "    samples_per_patient = N_SAMPLES_DEV // N_PATIENTS_DEV\n",
    "    groups_dev = np.repeat(np.arange(N_PATIENTS_DEV), samples_per_patient)\n",
    "    remaining_samples = N_SAMPLES_DEV % N_PATIENTS_DEV\n",
    "    if remaining_samples > 0:\n",
    "        groups_dev = np.concatenate([groups_dev, np.random.choice(N_PATIENTS_DEV, remaining_samples)])\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    np.random.shuffle(groups_dev)\n",
    "    print(f\"Generated X_dev shape: {X_dev.shape}, y_dev shape: {y_dev.shape}, groups_dev shape: {groups_dev.shape}\")\n",
    "\n",
    "\n",
    "# Define a simple baseline model\n",
    "model = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE)\n",
    "# -\n",
    "\n",
    "# ## 2. Hold-Out Validation (Simple Train/Validation Split)\n",
    "#\n",
    "# This is the simplest approach but often unreliable due to high variance. We split the *development* data into a single training set and a single validation set. The performance heavily depends on which specific samples end up in the validation set.\n",
    "\n",
    "# +\n",
    "# Perform a simple train/validation split ON THE DEVELOPMENT DATA\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_dev, y_dev,\n",
    "    test_size=0.25, # e.g., 75% train, 25% validation from the dev set\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_dev\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")\n",
    "\n",
    "# Train the model on the training part\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the validation part\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_proba_val = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "auc = roc_auc_score(y_val, y_proba_val)\n",
    "\n",
    "print(f\"\\nHold-Out Validation Performance (random_state={RANDOM_STATE}):\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC:      {auc:.4f}\")\n",
    "\n",
    "# Demonstrate variability by changing the random state\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(\n",
    "    X_dev, y_dev, test_size=0.25, random_state=RANDOM_STATE + 1, stratify=y_dev\n",
    ")\n",
    "model.fit(X_train_2, y_train_2)\n",
    "y_pred_val_2 = model.predict(X_val_2)\n",
    "y_proba_val_2 = model.predict_proba(X_val_2)[:, 1]\n",
    "accuracy_2 = accuracy_score(y_val_2, y_pred_val_2)\n",
    "auc_2 = roc_auc_score(y_val_2, y_proba_val_2)\n",
    "\n",
    "print(f\"\\nHold-Out Validation Performance (random_state={RANDOM_STATE + 1}):\")\n",
    "print(f\"Accuracy: {accuracy_2:.4f}\")\n",
    "print(f\"AUC:      {auc_2:.4f}\")\n",
    "print(\"\\nNote how the performance can change just by changing the random split!\")\n",
    "# -\n",
    "\n",
    "# ## 3. K-Fold Cross-Validation\n",
    "#\n",
    "# K-Fold CV addresses the variance issue of the hold-out method.\n",
    "# 1. Shuffle the dataset randomly.\n",
    "# 2. Split the dataset into K equal(ish) folds.\n",
    "# 3. For each fold `k`:\n",
    "#     * Use fold `k` as the validation set.\n",
    "#     * Use the remaining K-1 folds as the training set.\n",
    "#     * Train and evaluate the model.\n",
    "# 4. Average the performance scores from the K evaluations.\n",
    "#\n",
    "# This uses the data more effectively and gives a more stable estimate. Common K values are 5 or 10.\n",
    "\n",
    "# +\n",
    "N_SPLITS_KFOLD = 5\n",
    "kf = KFold(n_splits=N_SPLITS_KFOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Use cross_val_score for convenience\n",
    "# It handles the looping, training, and scoring automatically\n",
    "# Note: By default, cross_val_score uses the model's .score() method (accuracy for classifiers)\n",
    "# We can specify other metrics using the 'scoring' parameter.\n",
    "\n",
    "print(f\"--- Running {N_SPLITS_KFOLD}-Fold Cross-Validation ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "kfold_accuracies = cross_val_score(\n",
    "    model,\n",
    "    X_dev,\n",
    "    y_dev,\n",
    "    cv=kf,         # Use the KFold object\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1      # Use all available CPU cores\n",
    ")\n",
    "kfold_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nIndividual fold accuracies (K-Fold): {kfold_accuracies}\")\n",
    "print(f\"Mean accuracy: {kfold_accuracies.mean():.4f}\")\n",
    "print(f\"Std deviation: {kfold_accuracies.std():.4f}\")\n",
    "print(f\"Time taken:    {kfold_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "kfold_aucs = cross_val_score(\n",
    "    model, X_dev, y_dev, cv=kf, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "kfold_auc_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nIndividual fold AUCs (K-Fold): {kfold_aucs}\")\n",
    "print(f\"Mean AUC:      {kfold_aucs.mean():.4f}\")\n",
    "print(f\"Std deviation: {kfold_aucs.std():.4f}\")\n",
    "print(f\"Time taken:    {kfold_auc_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# Manual loop example (to see indices)\n",
    "print(\"\\n--- Manual K-Fold Loop Example (First 2 Folds) ---\")\n",
    "fold_counter = 1\n",
    "for train_index, val_index in kf.split(X_dev):\n",
    "    if fold_counter > 2: break\n",
    "    X_train_fold, X_val_fold = X_dev[train_index], X_dev[val_index]\n",
    "    y_train_fold, y_val_fold = y_dev[train_index], y_dev[val_index]\n",
    "\n",
    "    print(f\"\\nFold {fold_counter}:\")\n",
    "    print(f\"  Train indices: {train_index[:5]}...{train_index[-5:]} (Size: {len(train_index)})\")\n",
    "    print(f\"  Validation indices: {val_index[:5]}...{val_index[-5:]} (Size: {len(val_index)})\")\n",
    "\n",
    "    # Check class distribution in this fold (can be uneven with standard KFold)\n",
    "    train_dist = np.bincount(y_train_fold) / len(y_train_fold)\n",
    "    val_dist = np.bincount(y_val_fold) / len(y_val_fold)\n",
    "    print(f\"  Train class distribution: {train_dist}\")\n",
    "    print(f\"  Val class distribution:   {val_dist}\")\n",
    "\n",
    "    fold_counter += 1\n",
    "# -\n",
    "\n",
    "# **Note:** Standard K-Fold does not guarantee that the class proportions are maintained within each fold, which can be problematic for imbalanced datasets.\n",
    "\n",
    "# ## 4. Stratified K-Fold Cross-Validation\n",
    "#\n",
    "# Stratified K-Fold is a variation designed specifically for classification tasks, particularly when class imbalance exists. It ensures that each fold has approximately the **same percentage of samples from each target class** as the complete dataset.\n",
    "\n",
    "# +\n",
    "N_SPLITS_SKFOLD = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS_SKFOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"\\n--- Running {N_SPLITS_SKFOLD}-Fold Stratified Cross-Validation ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "skfold_accuracies = cross_val_score(\n",
    "    model, X_dev, y_dev, cv=skf, scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "skfold_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nIndividual fold accuracies (Stratified K-Fold): {skfold_accuracies}\")\n",
    "print(f\"Mean accuracy: {skfold_accuracies.mean():.4f}\")\n",
    "print(f\"Std deviation: {skfold_accuracies.std():.4f}\")\n",
    "print(f\"Time taken:    {skfold_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "skfold_aucs = cross_val_score(\n",
    "    model, X_dev, y_dev, cv=skf, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "skfold_auc_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nIndividual fold AUCs (Stratified K-Fold): {skfold_aucs}\")\n",
    "print(f\"Mean AUC:      {skfold_aucs.mean():.4f}\")\n",
    "print(f\"Std deviation: {skfold_aucs.std():.4f}\")\n",
    "print(f\"Time taken:    {skfold_auc_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# Manual loop example (to see stratification)\n",
    "print(\"\\n--- Manual Stratified K-Fold Loop Example (First 2 Folds) ---\")\n",
    "fold_counter = 1\n",
    "for train_index, val_index in skf.split(X_dev, y_dev): # Pass y for stratification\n",
    "    if fold_counter > 2: break\n",
    "    X_train_fold, X_val_fold = X_dev[train_index], X_dev[val_index]\n",
    "    y_train_fold, y_val_fold = y_dev[train_index], y_dev[val_index]\n",
    "\n",
    "    print(f\"\\nFold {fold_counter}:\")\n",
    "    print(f\"  Train indices: {train_index[:5]}...{train_index[-5:]} (Size: {len(train_index)})\")\n",
    "    print(f\"  Validation indices: {val_index[:5]}...{val_index[-5:]} (Size: {len(val_index)})\")\n",
    "\n",
    "    # Check class distribution in this fold (should be stratified)\n",
    "    train_dist = np.bincount(y_train_fold) / len(y_train_fold)\n",
    "    val_dist = np.bincount(y_val_fold) / len(y_val_fold)\n",
    "    print(f\"  Train class distribution: {train_dist}\")\n",
    "    print(f\"  Val class distribution:   {val_dist}\") # Should be similar to train and overall\n",
    "\n",
    "    fold_counter += 1\n",
    "# -\n",
    "\n",
    "# **Observation:** The mean scores might be similar between K-Fold and Stratified K-Fold if the dataset isn't heavily imbalanced or large enough. However, the standard deviation might be lower with Stratified K-Fold, and it's generally the safer choice for classification.\n",
    "\n",
    "# ## 5. Leave-One-Out Cross-Validation (LOOCV)\n",
    "#\n",
    "# LOOCV is an extreme case of K-Fold where K equals the number of samples (N).\n",
    "# 1. For each sample `i`:\n",
    "#     * Use sample `i` as the validation set (size 1).\n",
    "#     * Use the remaining N-1 samples as the training set.\n",
    "#     * Train and evaluate.\n",
    "# 2. Average the N performance scores.\n",
    "#\n",
    "# **Pros:** Uses maximum data for training in each step (low bias estimate). Deterministic (no randomness in splits).\n",
    "# **Cons:** Computationally **very expensive** (N model trainings). Can have high variance in the performance estimate (sensitive to individual points).\n",
    "\n",
    "# +\n",
    "loo = LeaveOneOut()\n",
    "n_splits_loo = loo.get_n_splits(X_dev)\n",
    "print(f\"\\n--- Running Leave-One-Out Cross-Validation ({n_splits_loo} Splits) ---\")\n",
    "\n",
    "# WARNING: This can be VERY slow for datasets of even moderate size.\n",
    "# Only run this section if X_dev is small or you have time.\n",
    "# Consider reducing N_SAMPLES in Notebook 0 if needed for faster demo.\n",
    "\n",
    "if n_splits_loo <= 500: # Set a reasonable limit for demo purposes\n",
    "    start_time = time.time()\n",
    "    loo_accuracies = cross_val_score(\n",
    "        model, X_dev, y_dev, cv=loo, scoring='accuracy', n_jobs=-1\n",
    "    )\n",
    "    loo_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\nMean accuracy (LOOCV): {loo_accuracies.mean():.4f}\")\n",
    "    print(f\"Std deviation: {loo_accuracies.std():.4f}\") # Std dev might be high\n",
    "    print(f\"Time taken:    {loo_time:.2f} seconds\")\n",
    "\n",
    "    # AUC is less meaningful with only one sample in the validation set,\n",
    "    # but cross_val_score can still compute it if the model provides probabilities.\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        loo_aucs = cross_val_score(\n",
    "             model, X_dev, y_dev, cv=loo, scoring='roc_auc', n_jobs=-1, error_score='raise'\n",
    "        )\n",
    "        loo_auc_time = time.time() - start_time\n",
    "        print(f\"\\nMean AUC (LOOCV):      {loo_aucs.mean():.4f}\")\n",
    "        print(f\"Std deviation: {loo_aucs.std():.4f}\")\n",
    "        print(f\"Time taken:    {loo_auc_time:.2f} seconds\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nCould not calculate AUC with LOOCV: {e}\")\n",
    "        print(\" (This often happens as AUC is undefined for a single validation sample).\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\nSkipping LOOCV execution as number of splits ({n_splits_loo}) is large.\")\n",
    "\n",
    "# -\n",
    "\n",
    "# ## 6. Summary\n",
    "#\n",
    "# We have explored basic CV techniques:\n",
    "# *   **Hold-Out:** Simple, but high variance. Not generally recommended for final evaluation.\n",
    "# *   **K-Fold:** Good general standard, balances bias/variance well. Use `shuffle=True`.\n",
    "# *   **Stratified K-Fold:** **Recommended for classification**, especially with imbalanced data. Ensures class proportions per fold.\n",
    "# *   **LOOCV:** Low bias, very high computational cost. Potentially high variance in estimate. Use only for very small datasets.\n",
    "#\n",
    "# In the next notebooks, we will cover CV techniques crucial for specific data types common in medical AI, such as grouped/patient data and time series data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
