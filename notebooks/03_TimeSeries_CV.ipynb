{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Notebook 3: Cross-Validation for Time Series Data\n",
    "#\n",
    "# ## Goals\n",
    "# * Understand why standard shuffled CV methods are incorrect for time-dependent data.\n",
    "# * Learn about **Lookahead Bias**.\n",
    "# * Implement time series cross-validation using `sklearn.model_selection.TimeSeriesSplit`.\n",
    "# * Visualize the training and validation indices used in time series CV.\n",
    "\n",
    "# ## 1. The Problem: Temporal Dependency\n",
    "#\n",
    "# Many datasets, especially in monitoring or forecasting scenarios, have an inherent **temporal order**. Examples:\n",
    "# *   Predicting patient deterioration based on vital signs over the last few hours.\n",
    "# *   Forecasting disease outbreaks based on weekly case counts.\n",
    "# *   Analyzing sequential events in EHRs.\n",
    "#\n",
    "# In these cases, the order of data points matters. The value at time `t` might depend on values at `t-1`, `t-2`, etc.\n",
    "#\n",
    "# **Why standard K-Fold fails:** Standard methods (like `KFold`, `StratifiedKFold` with `shuffle=True`) randomly shuffle the data before splitting. This breaks the temporal order. A model could be trained on data from the future (e.g., Wednesday, Friday) to predict data from the past (e.g., Monday), which is impossible in a real-world scenario.\n",
    "#\n",
    "# **Lookahead Bias:** Using future information to make predictions about the past or present leads to overly optimistic performance estimates that are not achievable in practice.\n",
    "\n",
    "# ## 2. The Solution: Time Series Cross-Validation\n",
    "#\n",
    "# Time series CV techniques respect the temporal order. They ensure that the validation set always consists of data points that occurred *after* the data points in the training set.\n",
    "#\n",
    "# **`TimeSeriesSplit` in Scikit-learn:**\n",
    "# This splitter yields folds where the training set grows (or slides) over time, and the validation set consists of the points immediately following the training set.\n",
    "#\n",
    "# ```\n",
    "# Fold 1: [----------] [validation]\n",
    "# Fold 2: [--------------------] [validation]\n",
    "# Fold 3: [------------------------------] [validation]\n",
    "# ...\n",
    "# ```\n",
    "# (`[]` denotes data points, `validation` is the set for testing in that fold)\n",
    "\n",
    "# ## 3. Setup and Generating Time Series Data\n",
    "#\n",
    "# Let's create some simple synthetic time series data. We'll create features `X_time` and a target `y_time`. For simplicity, we'll assume the data is already sorted chronologically.\n",
    "\n",
    "# +\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression # Example: Regression task\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Generate synthetic time series data\n",
    "N_SAMPLES_TIME = 300\n",
    "N_FEATURES_TIME = 3\n",
    "\n",
    "# Create a time index\n",
    "time_index = np.arange(N_SAMPLES_TIME)\n",
    "\n",
    "# Create features (e.g., lagged values, sine waves, random noise)\n",
    "X_time = np.zeros((N_SAMPLES_TIME, N_FEATURES_TIME))\n",
    "X_time[:, 0] = np.sin(time_index / 20) # A cyclical feature\n",
    "X_time[:, 1] = time_index / N_SAMPLES_TIME # A trend feature\n",
    "X_time[:, 2] = np.random.randn(N_SAMPLES_TIME) * 0.5 # Noise feature\n",
    "\n",
    "# Create a target variable that depends on past features and some noise\n",
    "y_time = (\n",
    "    0.8 * np.sin((time_index - 5) / 20) # Lagged sine wave\n",
    "    + 0.5 * ((time_index - 10) / N_SAMPLES_TIME) # Lagged trend\n",
    "    + np.random.randn(N_SAMPLES_TIME) * 0.3 # Noise\n",
    ")\n",
    "\n",
    "\n",
    "# Visualize the data (optional)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(time_index, X_time[:, 0], label='Feature 1 (Sine)')\n",
    "plt.plot(time_index, X_time[:, 1], label='Feature 2 (Trend)')\n",
    "plt.title('Synthetic Features')\n",
    "plt.legend()\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(time_index, y_time, label='Target Variable (y_time)', color='C0')\n",
    "plt.title('Synthetic Target Variable')\n",
    "plt.legend()\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Value')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Generated X_time shape: {X_time.shape}\")\n",
    "print(f\"Generated y_time shape: {y_time.shape}\")\n",
    "# -\n",
    "\n",
    "# ## 4. Applying TimeSeriesSplit\n",
    "#\n",
    "# We instantiate `TimeSeriesSplit` and use it with `cross_val_score`. Common parameters include:\n",
    "# *   `n_splits`: Number of folds to create.\n",
    "# *   `max_train_size`: Optional, to create a sliding window instead of an expanding one.\n",
    "# *   `gap`: Optional, number of samples to leave between train and test sets.\n",
    "\n",
    "# +\n",
    "# Define a model (e.g., Linear Regression for this synthetic task)\n",
    "model_time = LinearRegression()\n",
    "\n",
    "# Instantiate TimeSeriesSplit\n",
    "N_SPLITS_TIME = 5\n",
    "tscv = TimeSeriesSplit(n_splits=N_SPLITS_TIME) # Default: expanding window\n",
    "\n",
    "print(f\"\\n--- Running Time Series Cross-Validation ({N_SPLITS_TIME} Splits) ---\")\n",
    "\n",
    "# Use cross_val_score. Note 'neg_mean_squared_error' as score needs to be maximized.\n",
    "# We take the negative later.\n",
    "time_scores = cross_val_score(\n",
    "    model_time,\n",
    "    X_time,\n",
    "    y_time,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error', # Lower MSE is better, so maximize negative MSE\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Convert scores back to positive MSE\n",
    "time_mse_scores = -time_scores\n",
    "\n",
    "print(f\"\\nIndividual fold MSEs (TimeSeriesSplit): {time_mse_scores}\")\n",
    "print(f\"Mean MSE:      {time_mse_scores.mean():.4f}\")\n",
    "print(f\"Std deviation: {time_mse_scores.std():.4f}\")\n",
    "# -\n",
    "\n",
    "# ## 5. Visualizing TimeSeriesSplit Indices\n",
    "#\n",
    "# Let's manually iterate through the splits to see how the training and validation indices are assigned, confirming the temporal separation.\n",
    "\n",
    "# +\n",
    "def plot_cv_indices(cv, X, y, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices generated by a CV object.\"\"\"\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=plt.cm.coolwarm,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits))\n",
    "    ax.set(yticks=np.arange(n_splits) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample Index', ylabel=\"CV Iteration\",\n",
    "           ylim=[n_splits, -.2], xlim=[0, len(X)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "# Visualize TimeSeriesSplit\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "plot_cv_indices(tscv, X_time, y_time, ax, N_SPLITS_TIME)\n",
    "ax.legend([plt.Line2D(X_time,y_time,color=plt.cm.coolwarm(0.), lw=4)], ['Training set'], loc=(1.02, .8))\n",
    "ax.legend([plt.Line2D(X_time,y_time,color=plt.cm.coolwarm(1.), lw=4)], ['Validation set'], loc=(1.02, .6))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print first few train/test indices from the generator\n",
    "print(\"\\n--- Manual Time Series Split Example (First 2 Folds) ---\")\n",
    "fold_counter = 1\n",
    "for train_index, val_index in tscv.split(X_time):\n",
    "     if fold_counter > 2: break\n",
    "     print(f\"\\nFold {fold_counter}:\")\n",
    "     print(f\"  Train indices (Range): {train_index.min()}-{train_index.max()} (Size: {len(train_index)})\")\n",
    "     print(f\"  Val indices (Range):   {val_index.min()}-{val_index.max()} (Size: {len(val_index)})\")\n",
    "     # Verify temporal order\n",
    "     print(f\"  Validation starts after Train ends: {val_index.min() > train_index.max()}\")\n",
    "     fold_counter += 1\n",
    "# -\n",
    "\n",
    "# **Observation:** The visualization clearly shows that the validation set (red) always comes *after* the training set (blue) in each CV iteration, respecting the temporal order. The training set size increases with each fold in the default expanding window setup.\n",
    "\n",
    "# ## 6. Conclusion\n",
    "#\n",
    "# When dealing with time-ordered data, using specialized cross-validation techniques like `TimeSeriesSplit` is crucial to avoid lookahead bias and obtain realistic performance estimates. Randomly shuffling time series data before applying standard K-Fold CV will lead to misleadingly optimistic results. Always consider the nature of your data and choose the appropriate CV strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
